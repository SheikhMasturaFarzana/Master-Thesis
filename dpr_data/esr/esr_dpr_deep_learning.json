["deep-learning speech synthesis", "deep-learning semi-supervised embedding nonlinear embedding algorithm popular use shallow</i semi-supervised learning technique kernel method apply deep multilayer architecture regularizer output layer layer architecture provide simple alternative exist approach deep</i learn whilst yield competitive error rate compare method exist shallow</i semi-supervised technique", "fast learn algorithm deep belief net use complementary prior eliminate explain away effect inference difficult densely-connected belief net hide layer complementary prior derive fast greedy algorithm learn deep direct belief network layer time provide layer form undirected associative memory fast greedy algorithm initialize slow learning procedure fine-tune weight contrastive version wake-sleep algorithm fine-tuning network hidden layer form good generative model joint distribution handwritten digit image label generative model digit classification good discrimi-native learning algorithm low-dimensional manifold digit lie model long ravine free-energy landscape top-level associative memory easy explore ravine direct connection display associative memory mind", "learn opencv computer-vision opencv library software", "deep-learne detect robotic grasp consider problem detect robotic grasp rgb-d view scene contain object work apply deep-learning approach solve problem avoid time-consuming hand-design feature present main challenge need evaluate huge number candidate grasp order detection fast robust present two-step cascade structure deep network detection re-evaluate second network feature fast run effectively prune unlikely candidate grasp second feature slow run detection second need handle multimodal inputs present method apply structured regularization weight base multimodal group reg-ularization demonstrate method outperform previous state-of-the-art method robotic grasp detection successfully execute grasp baxter robot", "deep-learning hessian-free optimization develop nd-order optimization method base hessian-free approach apply train deep auto-encoder pre-training obtain result superior report hinton salakhutdinov task consider method practical easy use scale nicely large dataset limit applicability auto-encoder specific model class discuss issue pathological curvature possible explanation difficulty deep-learning nd-order optimization method particular effectively deal", "deep-learne cots hpc system scale deep-learning algorithm lead increase performance benchmark task enable discovery complex high-level feature recent effort train extremely large network parameter rely cloud-like computing infrastructure thousand cpu core paper present technical detail result system base commodity off-the-shelf high performance computing cots hpc technology cluster gpu server infini-band interconnect mpi system able train parameter network machine couple day scale network parameter machine infrastructure easily marshal approach enable wider-spread research extremely large neural network", "learn deep architecture ai theoretical result suggest order learn kind complicated function represent high-level abstraction vision language ai-level task need deep architecture deep architecture compose multiple level non-linear operation neural net hide layer complicated propositional formula re-use sub-formulae search parameter space deep architecture difficult task learn algorithm deep belief network recently propose tackle problem notable success beat state-of-the-art certain area paper discuss motivation principle learn algorithm deep architecture particular exploit building block unsupervise learning single-layer model restrict boltzmann machine construct deep model deep belief network", "data-intensive question-answering", "continuous learning human activity model deep net learn activity model continuously stream video immensely important problem video surveillance video indexing etc research human activity recognition mainly focus learn static model consider training instance label present advance streaming video new instance continuously arrive label work propose continuous human activity learning framework stream video intricately tie deep network active learning allow automatically select suitable feature advantage incoming unlabeled instance improve exist model incrementally segmented activity stream video learn feature unsupervised manner deep network use active learning reduce manual labeling class conduct rigorous experiment challenge human activity dataset demonstrate effectiveness framework learn human activity model continuously", "large scale distribute deep network recent work unsupervised feature learning deep-learning able train large model dramatically improve performance paper consider problem train deep network billion parameter thousand cpu core develop software framework distbelief utilize compute cluster thousand machine train large model framework develop algorithm large-scale distribute training downpour sgd asynchronous stochastic gradient descent procedure support large number model replica ii sandblaster framework support variety distribute batch optimization procedure include distribute implementation l-bfgs downpour sgd sandblaster l-bfgs increase scale speed deep network training successfully system train deep network large previously report literature achieve state-of-the-art performance imagenet visual object recognition task image category technique dramatically accelerate training modestly-sized deep network commercial speech recognition service focus report performance method apply train large neural network underlying algorithm applicable gradient-based machine learn algorithm", "deep-learning neural network overview recent year deep artificial neural network include recurrent win numerous contest pattern recognition machine learn historical survey compactly summarise relevant work previous millennium shallow deep learner distinguish depth credit assignment path chain possibly learnable causal link action effect review deep supervise learning recapitulate history backpropagation unsupervised learning reinforcement learning evolutionary computation indirect search short program encode deep large network preface preprint invite deep-learning dl overview goal assign credit contribute present state art acknowledge limitation attempt achieve goal dl research community view continually evolve deep network scientist influence complex way start recent dl result try trace origin relevant idea past half century local search follow citation citation backwards time dl publication properly acknowledge earlier relevant work additional global search strategy employ aid consult numerous neural network expert result present preprint consist reference expert selection bias miss important work related bias surely introduce special familiarity work dl research group past quarter-century reason work view merely snapshot ongoing credit assignment process help improve hesitate send correction suggestion juergen@idsia ch", "semi-supervised learn literature survey", "introductory technique computer-vision", "multimodal deep-learne deep network successfully apply unsupervised feature learn single modality text image audio work propose novel application deep network learn feature multiple modality present series task multimodal learning train deep network learn feature address task particular demonstrate cross modality feature learning feature modality video learn multiple modality audio video present feature learning time furthermore learn share representation modality evaluate unique task classifier train audio-only datum test video-only datum vice-versa model validate cuave avlet-ter dataset audiovisual speech classification demonstrate best publish visual speech classification avletter effective share representation learning", "lexical chain question-answering", "open-domain question-answering", "learn deep generative model learn deep generative model build intelligent system capable extract high-level representation high-dimensional sensory data lie core solve ai relate task include object recognition speech perception language understanding theoretical biological argument strongly suggest build system require model deep architecture involve layer nonlinear processing aim thesis demonstrate deep generative model contain layer latent variable million parameter learn efficiently learned high-level feature representation successfully apply wide spectrum application domain include visual object recognition information retrieval classification regression task addition similar method nonlinear dimensionality reduction thesis focus analysis application probabilistic generative model deep belief network deep hierarchical model learn useful feature representation large supply unlabeled sensory input learned high-level representation capture lot structure input datum useful subsequent problem-specific task classification regression information retrieval task unknown generative model train second thesis introduce new learn algorithm different type hierarchical probabilistic model deep boltzmann machine like deep belief network deep boltzmann machine potential learn internal representation increasingly complex high layer promising way solve object speech recognition problem unlike deep belief network exist model deep architecture approximate inference procedure addition fast bottom-up pass incorporate top-down feedback allow deep boltzmann machine better propagate uncertainty ambiguous input ii acknowledgement foremost like thank advisor geoffrey hinton incredible advisor amazing teacher provide warm outstanding intellectual environment university toronto like thank sam roweis second advisor committee member radford neal rich zemel valuable feedback support guidance thank member toronto machine learning group interesting inspiring discussion thank parent family continue support finally special", "information-geometry neuro-manifolds", "information-geometry information theory machine learning", "level set method computer-vision", "deep boltzmann machine present new learn algorithm boltz-mann machine contain layer hide variable data-dependent expectation estimate variational approximation tend focus single mode data-independent expectation approximate persistent markov chain use different technique estimate type expectation enter gradient log-likelihood practical learn boltzmann machine multiple hide layer million parameter learning efficient layer-by-layer pre-training phase allow variational inference initialize single bottom-up pass present result mnist norb dataset deep boltzmann machine learn good generative model perform handwritten digit visual object recognition task", "found cryptography oblivious transfer suppose netmail erratically cen-sore captain yossarian send message censor bit message probability replace censor bit reserve character verse concept redundancy real problem question actually turn advantage answer question strongly aarmative protocol commonly know oblivious transfer simulate sophisticated protocol know oblivious circuit evaluation((y communication channel completely noninteractive zero-knowledge proof statement np result use complexity-theoretic assumption application variety model oblivious transfer", "paraphrase-driven learn open question-answering study question-answere machine learn problem induce function map open-domain question query database web extraction large community-authored question-paraphrase corpus demonstrate possible learn semantic lexicon linear rank function manually annotate question approach automatically generalize seed lexicon include scal-able parallelize perceptron parameter estimation scheme experiment approach quadruple recall seed lexicon loss precision", "question-answere subgraph embedding paper present system learn answer question broad range topic knowledge base hand-crafted feature model learn low-dimensional embedding word knowledge base constituent representation score natural language question candidate answer train system pair question structured representation answer pair question paraphrase yield competitive result recent benchmark literature", "natural language question-answering view", "real-time computer-vision opencv mobile computer-vision technology soon ubiquitous touch interface", "information-geometry u-boost bregman divergence aim extend adaboost u-boost paradigm build strong classification machine set weak learning machine geometric understanding bregman divergence define generic function convex lead u-boost method framework information-geometry finite measure function label set propose version u-boost learn algorithm domain restrict space probability function sequential step observe adjacent initial classifier associate right triangle scale bregman divergence pythagorean relation lead mild convergence property u-boost algorithm -pron- algorithm statistical discussion consistency robustness elucidate property u-boost method base probabilistic assumption training datum", "knowledge-powered deep-learning word embed basis apply deep-learning solve natural language processing task obtain high-quality distribute representation word word embedding large text datum text usually contain incomplete ambiguous information necessity leverage extra knowledge understand fortunately text contain well-defined morphological syntactic knowledge large text web enable extraction plenty semantic knowledge sense design novel deep-learning algorithm system order leverage knowledge compute effective word embed-ding paper conduct empirical study capacity leverage morphological syntactic semantic knowledge achieve high-quality word embedding study explore type knowledge define new basis word representation provide additional input information serve auxiliary supervision deep-learning respectively experiment analogical reasoning task word similarity task word completion task demonstrate knowledge-powered deep-learning enhance effectiveness word embedding", "information-geometry turbo decode", "joint deep-learning pedestrian detection feature extraction deformation handling occlusion handling important component pedestrian detection exist method learn design component individually sequentially interaction component explore paper propose jointly learn order maximize strength cooperation formulate component joint deep-learning framework propose new deep network architecture establish automatic mutual interaction component deep model achieve reduction average miss rate compare current best-performing pedestrian detection approach large caltech benchmark dataset", "exact solution nonlinear dynamic learn deep linear neural network despite widespread practical success deep-learning method theoretical understanding dynamic learn deep neural network remain sparse attempt bridge gap theory practice deep-learning systematically analyze learn dynamic restrict case deep linear neural network despite linearity input-output map network nonlinear gradient descent dynamic weight change addition new hide layer deep linear network exhibit nonlinear learn phenomena similar simulation nonlinear network include long plateaus follow rapid transition low error solution fast convergence greedy unsupervised pretraine initial condition random initial condition provide analytical description phenomenon find new exact solution nonlinear dynamic deep-learning theoretical analysis reveal surprising finding depth network approach infinity learn speed remain finite special class initial condition weight deep network incur finite depth independent delay learn speed relative shallow network certain condition training datum unsupervised pretraining find special class initial condition scale random gaussian initialization exhibit new class random orthogonal initial condition weight like unsupervise pre-training enjoy depth independent learning time initial condition lead faithful propagation gradient deep nonlinear network long operate special regime know edge chaos deep-learning method realize impressive performance range application visual object classification speech recognition natural language processing success achieve despite noted difficulty train deep architecture explanation difficulty deep-learning advance literature include presence local minimum low curvature region saturate nonlinearitie exponential growth decay back-propagated gradient furthermore neural network simulation observe", "deep-learning representation look forward deep-learning research aim discover learning algorithm discover multiple level distribute representation high level represent abstract concept study deep-learning lead impressive theoretical result learn algorithm breakthrough experiment challenge lie ahead paper propose examine challenge center question scale deep-learning algorithm large model dataset reduce optimization difficulty ill-conditioning local minimum design efficient powerful inference sampling procedure learn disentangle factor variation underlie observed datum propose forward-looking research direction aim overcome challenge deep-learning emerge approach machine learn research community deep-learning algorithm propose recent year machine learning system discovery multiple level representation important empirical success number traditional ai application computer-vision natural language processing bengio bengio et al review bengio chapter book montavon muller practical guideline deep-learning attract attention academic industrial community company like google microsoft apple ibm baidu invest deep-learning widely distribute product consumer aim speech recognition deep-learning object recognition google goggles image music information retrieval google image search google music computational advertising corrado deep-learning building block restricted boltzmann machine rbm crucial win entry million-dollar machine learning competition netflix competition salakhutdinov et al et al new york times cover subject twice front-page article series article include new york times article cover recent event application deep-learning major kaggle competition drug discovery example deep-learning-the big datum science breakthrough decade recently google buy acqui-hired company dnnresearch create university toronto professor geoffrey hinton founder lead researcher deep-learning phd student ilya sutskever alex krizhevsky press", "deep residual learning image recognition deep neural network difficult train present residual learning framework ease training network substantially deep previously explicitly reformulate layer learn residual function reference layer input instead learn unreferenced function provide comprehensive empirical evidence residual network easy optimize gain accuracy considerably increase depth imagenet dataset evaluate residual net depth deep vgg net low complexity ensemble residual net achieve error imagenet test set result win 1st place ilsvrc classification task present analysis cifar-10 layer depth representation central importance visual recognition task solely extremely deep representation obtain relative improvement coco object detection dataset deep residual net foundation submission ilsvrc coco competition win 1st place task imagenet detection imagenet local-ization coco detection coco segmentation", "trec question-answering track", "common randomness information theory cryptography secret sharing", "unsupervised learning hierarchical representation convolutional deep belief network interest unsupervise learning hierarchical generative model deep belief network dbns scale model full-sized high-dimensional image remain difficult problem address problem present convolutional deep belief network</i hierarchical generative model scale realistic image size model translation-invariant support efficient bottom-up top-down probabilistic inference key approach probabilistic max-pooling</i novel technique shrink representation high layer probabilistically sound way experiment algorithm learn useful high-level visual feature object unlabeled image object natural scene demonstrate excellent performance visual recognition task model perform hierarchical bottom-up top-down inference full-sized image", "teach geometry deformable model current object class recognition system typically target bound box localization encourage benchmark data set pascal voc suitable detection individual object higher-level application scene understanding object tracking benefit fine-grained object hypothese incorporate geometric information viewpoint location individual paper help narrow representational gap ideal input scene understanding system object class detector output design detector particularly tailor geometric reasoning particular extend successful discriminatively train deformable model include estimate viewpoint consistent viewpoint experimentally verify add geometric information come minimal performance loss bound box localization outper-form prior work viewpoint estimation ultra-wide baseline matching", "iplant collaborative cyberinfrastructure plant biology iplant collaborative iplant united states national science foundation nsf fund project aim create innovative comprehensive foundational cyberinfrastructure support plant biology research pscic iplant develop cyberinfrastructure uniquely enable scientist diverse field comprise plant biology address grand challenge new way stimulate facilitate cross-disciplinary research promote biology computer science research interaction train generation scientist use cyberinfrastructure research education meeting humanity project demand agricultural forest product expectation natural ecosystem manage sustainably require synergy application information technology iplant cyberinfrastructure design base unprecedented period research community input leverage development high-performance computing datum storage cyberinfrastructure physical science iplant open-source project application programming interface allow community extend infrastructure meet need iplant sponsor community-driven workshop address specific", "information-geometry", "multilingual question-answering link datum qald-3 lab overview instalment open challenge question-answere link datum qald-3 conduct half-day lab clef di erently previous edition challenge qald-3 strong emphasis multilinguality ere task multilingual question-answering ontology lexicalization submission receive attract team submit system result provide dataset paper provide overview qald-3 discuss approach experiment participate system obtain result", "lcc tool question-answering"]